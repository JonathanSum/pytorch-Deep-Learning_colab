{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ch5_optim.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN7egfjSft8v479S3TvOzdW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JonathanSum/pytorch-Deep-Learning_colab/blob/master/Ch5_optim.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgDiXWu7HnmF"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsZ9IV-mBcaB",
        "outputId": "8980b8f6-db05-4dd3-8145-5380d15da649"
      },
      "source": [
        "import torch.optim as optim\r\n",
        "dir(optim)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ASGD',\n",
              " 'Adadelta',\n",
              " 'Adagrad',\n",
              " 'Adam',\n",
              " 'AdamW',\n",
              " 'Adamax',\n",
              " 'LBFGS',\n",
              " 'Optimizer',\n",
              " 'RMSprop',\n",
              " 'Rprop',\n",
              " 'SGD',\n",
              " 'SparseAdam',\n",
              " '__builtins__',\n",
              " '__cached__',\n",
              " '__doc__',\n",
              " '__file__',\n",
              " '__loader__',\n",
              " '__name__',\n",
              " '__package__',\n",
              " '__path__',\n",
              " '__spec__',\n",
              " '_multi_tensor',\n",
              " 'functional',\n",
              " 'lr_scheduler',\n",
              " 'swa_utils']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqtW6kqeJfm1"
      },
      "source": [
        "Here SGD stands for stochastic gradient descent. Actually, the optimizer itself is exactly a\r\n",
        "vanilla gradient descent (as long as the momentum argument is set to 0.0, which is the\r\n",
        "default)\r\n",
        "Pg. 129."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YJ6bJdvBg3G"
      },
      "source": [
        "params = torch.tensor([1.0, 0.0], requires_grad=True)\r\n",
        "learning_rate = 1e-5\r\n",
        "optimizer = optim.SGD([params], lr=learning_rate)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yv7_6e5vY3vk"
      },
      "source": [
        "def model(t_u, w, b):\r\n",
        "    return w * t_u + b\r\n",
        "\r\n",
        "def loss_fn(t_p, t_c):\r\n",
        "    squared_diffs = (t_p - t_c)**2\r\n",
        "    return squared_diffs.mean()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5k9BasrXY7wk"
      },
      "source": [
        "t_c = [0.5, 14.0, 15.0, 28.0, 11.0, 8.0, 3.0, -4.0, 6.0, 13.0, 21.0]\r\n",
        "t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4]\r\n",
        "t_c = torch.tensor(t_c)\r\n",
        "t_u = torch.tensor(t_u)\r\n",
        "t_un = 0.1 * t_u"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_47ko1ewHmO6",
        "outputId": "b5f8c48b-3d0b-44e9-9e0b-69d3e4dd8413"
      },
      "source": [
        "params = torch.tensor([1.0, 0.0], requires_grad=True)\r\n",
        "learning_rate = 1e-2\r\n",
        "\r\n",
        "optimizer = optim.SGD([params], lr=learning_rate)\r\n",
        "\r\n",
        "t_p = model(t_un, *params)\r\n",
        "loss = loss_fn(t_p, t_c)\r\n",
        "\r\n",
        "optimizer.zero_grad()\r\n",
        "loss.backward()\r\n",
        "optimizer.step()\r\n",
        "\r\n",
        "params"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.7761, 0.1064], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9p-pZT1iLwb"
      },
      "source": [
        "def training_loop(n_epochs, optimizer, params, t_u, t_c):\r\n",
        "    for epoch in range(1, n_epochs + 1):\r\n",
        "        t_p = model(t_u, *params)\r\n",
        "        loss = loss_fn(t_p, t_c)\r\n",
        "\r\n",
        "        optimizer.zero_grad()\r\n",
        "        loss.backward()\r\n",
        "        optimizer.step()\r\n",
        "\r\n",
        "        if epoch % 500 == 0:\r\n",
        "            print('Epoch %d, Loss %f' % (epoch, float(loss)))\r\n",
        "    return params"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFGf3URfZNfO",
        "outputId": "c8d9a70b-a34f-4b0a-9500-c8e5611811d9"
      },
      "source": [
        "params = torch.tensor([1.0, 0.0], requires_grad=True)\r\n",
        "learning_rate = 1e-2\r\n",
        "optimizer = optim.SGD([params], lr=learning_rate)\r\n",
        "\r\n",
        "training_loop(\r\n",
        "    n_epochs = 5000,\r\n",
        "    optimizer = optimizer,\r\n",
        "    params = params,\r\n",
        "    t_u = t_un,\r\n",
        "    t_c = t_c)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 500, Loss 7.860120\n",
            "Epoch 1000, Loss 3.828538\n",
            "Epoch 1500, Loss 3.092191\n",
            "Epoch 2000, Loss 2.957698\n",
            "Epoch 2500, Loss 2.933134\n",
            "Epoch 3000, Loss 2.928648\n",
            "Epoch 3500, Loss 2.927830\n",
            "Epoch 4000, Loss 2.927679\n",
            "Epoch 4500, Loss 2.927652\n",
            "Epoch 5000, Loss 2.927647\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  5.3671, -17.3012], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwpRVkW7iIgu",
        "outputId": "c04d6718-5105-4464-9502-3d9d04eee7f3"
      },
      "source": [
        "params = torch.tensor([1.0, 0.0], requires_grad=True)\r\n",
        "learning_rate = 1e-1\r\n",
        "optimizer = optim.Adam([params], lr=learning_rate)\r\n",
        "\r\n",
        "training_loop(\r\n",
        "    n_epochs = 2000,\r\n",
        "    optimizer = optimizer,\r\n",
        "    params = params,\r\n",
        "    t_u = t_u,\r\n",
        "    t_c = t_c)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 500, Loss 7.612900\n",
            "Epoch 1000, Loss 3.086700\n",
            "Epoch 1500, Loss 2.928579\n",
            "Epoch 2000, Loss 2.927644\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  0.5367, -17.3021], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVTsQijNnM_E",
        "outputId": "fa7bf8d5-7ae9-4ca1-f842-9887989b6a58"
      },
      "source": [
        "params = torch.tensor([1.0, 0.0], requires_grad=True)\r\n",
        "learning_rate = 1e-1\r\n",
        "optimizer = optim.Adam([params], lr=learning_rate)\r\n",
        "\r\n",
        "training_loop(\r\n",
        "    n_epochs = 2000,\r\n",
        "    optimizer = optimizer,\r\n",
        "    params = params,\r\n",
        "    t_u = t_u,\r\n",
        "    t_c = t_c)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 500, Loss 7.612900\n",
            "Epoch 1000, Loss 3.086700\n",
            "Epoch 1500, Loss 2.928579\n",
            "Epoch 2000, Loss 2.927644\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  0.5367, -17.3021], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Bce3ZLLNrmu",
        "outputId": "de2dcb73-6054-4b2a-add9-3d7be0b3a376"
      },
      "source": [
        "n_samples = t_u.shape[0]\r\n",
        "n_val = int(0.2 * n_samples)\r\n",
        "\r\n",
        "shuffled_indices = torch.randperm(n_samples)\r\n",
        "\r\n",
        "train_indices = shuffled_indices[:-n_val]\r\n",
        "val_indices = shuffled_indices[-n_val:]\r\n",
        "\r\n",
        "train_indices, val_indices"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 9, 10,  8,  0,  4,  6,  3,  7,  1]), tensor([2, 5]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZjnVDwMPu0y"
      },
      "source": [
        "train_t_u = t_u[train_indices]\r\n",
        "train_t_c = t_c[train_indices]\r\n",
        "\r\n",
        "val_t_u = t_u[val_indices]\r\n",
        "val_t_c = t_c[val_indices]\r\n",
        "\r\n",
        "train_t_un = 0.1 * train_t_u\r\n",
        "val_t_un = 0.1 * val_t_u"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDIMm1SxO7Dn",
        "outputId": "fdd5d9ff-6c61-4f70-ff23-1b1563eb7bc7"
      },
      "source": [
        "train_t_un, train_t_u"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([6.0400, 6.8400, 4.8400, 3.5700, 5.6300, 3.3900, 8.1900, 2.1800, 5.5900]),\n",
              " tensor([60.4000, 68.4000, 48.4000, 35.7000, 56.3000, 33.9000, 81.9000, 21.8000,\n",
              "         55.9000]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tzZJmzhEXof",
        "outputId": "337416f5-0069-44cc-9e33-b081eced3de5"
      },
      "source": [
        "train_t_c"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([13.0000, 21.0000,  6.0000,  0.5000, 11.0000,  3.0000, 28.0000, -4.0000,\n",
              "        14.0000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6yo5LblRKXa"
      },
      "source": [
        "train_t_u = t_u[train_indices]\r\n",
        "train_t_c = t_c[train_indices]\r\n",
        "val_t_u = t_u[val_indices]\r\n",
        "val_t_c = t_c[val_indices]\r\n",
        "train_t_un = 0.1 * train_t_u\r\n",
        "val_t_un = 0.1 * val_t_u"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5fEN17PTwfG"
      },
      "source": [
        "def training_loop(n_epochs, optimizer, params, train_t_u, val_t_u,\r\n",
        "                  train_t_c, val_t_c):\r\n",
        "    for epoch in range(1, n_epochs + 1):\r\n",
        "        train_t_p = model(train_t_u, *params)\r\n",
        "        train_loss = loss_fn(train_t_p, train_t_c)\r\n",
        "\r\n",
        "        val_t_p = model(val_t_u, *params)\r\n",
        "        val_loss = loss_fn(val_t_p, val_t_c)\r\n",
        "\r\n",
        "        optimizer.zero_grad()\r\n",
        "        train_loss.backward()\r\n",
        "        optimizer.step()\r\n",
        "\r\n",
        "        if epoch <= 3 or epoch % 500 == 0:\r\n",
        "            print(f\"Epoch {epoch}, Training loss {train_loss.item():.4f},\"\r\n",
        "                  f\" Validation loss {val_loss.item():.4f}\")\r\n",
        "    return params"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7hnL5eQTOeP",
        "outputId": "c78bb466-3329-40bc-f10e-8344ea79b4a8"
      },
      "source": [
        "params = torch.tensor([1.0, 0.0], requires_grad=True)\r\n",
        "learning_rate = 1e-2\r\n",
        "optimizer = optim.SGD([params], lr=learning_rate)\r\n",
        "\r\n",
        "training_loop(\r\n",
        "    n_epochs = 2000,\r\n",
        "    optimizer = optimizer,\r\n",
        "    params = params,\r\n",
        "    train_t_u = train_t_un,\r\n",
        "    val_t_u = val_t_un,\r\n",
        "    train_t_c = train_t_c,\r\n",
        "    val_t_c = val_t_c)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, Training loss 87.7848, Validation loss 46.9723\n",
            "Epoch 2, Training loss 42.9149, Validation loss 10.2668\n",
            "Epoch 3, Training loss 35.9266, Validation loss 6.3460\n",
            "Epoch 500, Training loss 7.4964, Validation loss 2.4492\n",
            "Epoch 1000, Training loss 3.8917, Validation loss 1.4560\n",
            "Epoch 1500, Training loss 3.4204, Validation loss 1.1822\n",
            "Epoch 2000, Training loss 3.3588, Validation loss 1.0943\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  5.2814, -16.8441], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXdT0M4D9qIR"
      },
      "source": [
        "We should not think that using torch.no_grad necessarily implies that<br> the outputs do not require gradients.<br>\r\n",
        "There are particular circumstances (involving views, as discussed in<br> section 3.8.1) in which requires_grad<br>\r\n",
        "is not set to False even when created in a no_grad context. It is best<br> to use the detach function if we need<br>\r\n",
        "to be sure.<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlyBl31lTUF3"
      },
      "source": [
        "def training_loop(n_epochs, optimizer, params, train_t_u, val_t_u,\r\n",
        "                  train_t_c, val_t_c):\r\n",
        "    for epoch in range(1, n_epochs + 1):\r\n",
        "        train_t_p = model(train_t_u, *params)\r\n",
        "        train_loss = loss_fn(train_t_p, train_t_c)\r\n",
        "\r\n",
        "        with torch.no_grad():\r\n",
        "              val_t_p = model(val_t_u, *params)\r\n",
        "              val_loss = loss_fn(val_t_p, val_t_c)\r\n",
        "              assert val_loss.requires_grad == False\r\n",
        "\r\n",
        "        optimizer.zero_grad()\r\n",
        "        train_loss.backward()\r\n",
        "        optimizer.step()\r\n",
        "\r\n",
        "        if epoch <= 3 or epoch % 500 == 0:\r\n",
        "            print(f\"Epoch {epoch}, Training loss {train_loss.item():.4f},\"\r\n",
        "                  f\" Validation loss {val_loss.item():.4f}\")\r\n",
        "    return params"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEF4tyD4A3VL"
      },
      "source": [
        "def calc_forward(t_u, t_c, is_train):\r\n",
        "    with torch.set_grad_enabled(is_train):\r\n",
        "        t_p = model(t_u, *params)\r\n",
        "        loss = loss_fn(t_p, t_c)\r\n",
        "    return loss"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEq-5MeGDuGD",
        "outputId": "1d2de5d8-b1b7-4ef5-c83c-9fb71f969b8d"
      },
      "source": [
        "params = torch.tensor([1.0, 0.0], requires_grad=True)\r\n",
        "learning_rate = 1e-2\r\n",
        "optimizer = optim.SGD([params], lr=learning_rate)\r\n",
        "\r\n",
        "training_loop(\r\n",
        "    n_epochs = 2000,\r\n",
        "    optimizer = optimizer,\r\n",
        "    params = params,\r\n",
        "    train_t_u = train_t_un,\r\n",
        "    val_t_u = val_t_un,\r\n",
        "    train_t_c = train_t_c,\r\n",
        "    val_t_c = val_t_c)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, Training loss 87.7848, Validation loss 46.9723\n",
            "Epoch 2, Training loss 42.9149, Validation loss 10.2668\n",
            "Epoch 3, Training loss 35.9266, Validation loss 6.3460\n",
            "Epoch 500, Training loss 7.4964, Validation loss 2.4492\n",
            "Epoch 1000, Training loss 3.8917, Validation loss 1.4560\n",
            "Epoch 1500, Training loss 3.4204, Validation loss 1.1822\n",
            "Epoch 2000, Training loss 3.3588, Validation loss 1.0943\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  5.2814, -16.8441], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgSx4BkrDTnW"
      },
      "source": [
        "Exercise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJk0Ty7YDPDS"
      },
      "source": [
        "def model(t_u, w1, w2, b):\r\n",
        "    return w2 * t_u ** 2 + w1 * t_u + b"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QS7RJ9xPHx2Q"
      },
      "source": [
        "def model(t_u, w1, w2, b):\r\n",
        "    return w2 * t_u ** 2 + w1 * t_u + b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tu_2HsQoGER2"
      },
      "source": [
        "def model(t_u, w1, b):\r\n",
        "    return w1 * t_u + b"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WM8evKJbFP6i",
        "outputId": "06747607-8839-43fa-9af1-a6b4085b8acd"
      },
      "source": [
        "params = torch.tensor([1.0, 1.0, 0.0], requires_grad=True)\r\n",
        "learning_rate = 1e-2\r\n",
        "optimizer = optim.SGD([params], lr=learning_rate)\r\n",
        "\r\n",
        "training_loop(\r\n",
        "    n_epochs = 2000,\r\n",
        "    optimizer = optimizer,\r\n",
        "    params = params,\r\n",
        "    train_t_u = train_t_un,\r\n",
        "    val_t_u = val_t_un,\r\n",
        "    train_t_c = train_t_c,\r\n",
        "    val_t_c = val_t_c)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, Training loss 710.1439, Validation loss 521.2211\n",
            "Epoch 2, Training loss 390641.4062, Validation loss 280429.8750\n",
            "Epoch 3, Training loss 219770464.0000, Validation loss 157970176.0000\n",
            "Epoch 500, Training loss nan, Validation loss nan\n",
            "Epoch 1000, Training loss nan, Validation loss nan\n",
            "Epoch 1500, Training loss nan, Validation loss nan\n",
            "Epoch 2000, Training loss nan, Validation loss nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([nan, nan, nan], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjSxpvSKHLP4"
      },
      "source": [
        "5.7 Exercise<br>\r\n",
        "1 Redefine the model to be w2 * t_u ** 2 + w1 * t_u + b.<br>\r\n",
        "a What parts of the training loop, and so on, need to change to<br> accommodate<br>\r\n",
        "this redefinition?<br>\r\n",
        "b What parts are agnostic to swapping out the model?<br>\r\n",
        "c Is the resulting loss higher or lower after training?<br>\r\n",
        "d Is the actual result better or worse?<br>\r\n",
        "\r\n",
        "a. That is the params, and we need to watch out the order of params<br> that is being passed into the model.<br>\r\n",
        "b. w2.<br>\r\n",
        "c. higher<br>\r\n",
        "d. worse<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIky0vNeHw8J"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}